<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Chapter 3: Inference for Simple Linear Regression</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs-2.11/header-attrs.js"></script>
    <link href="libs/panelset-0.2.6/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.2.6/panelset.js"></script>
    <script src="libs/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <link href="libs/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view-0.2.6/tile-view.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="extra.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Chapter 3: Inference for Simple Linear Regression
## Part 3: Section 3.4-3.5
### Applied Statistics II

---

class: highlight-last-item










&lt;style type="text/css"&gt;
.highlight-last-item &gt; ul &gt; li,
.highlight-last-item &gt; ol &gt; li {
  opacity: 0.5;
}
.highlight-last-item &gt; ul &gt; li:last-of-type,
.highlight-last-item &gt; ol &gt; li:last-of-type {
  opacity: 1;
}
&lt;/style&gt;

# Outline 

- Interaction model

--

- Polynomial regression

  - Quadratic model
  
--
  
- Second-order model

--

- Multicollinearity

  - Variance Inflation Factor (VIF)

---

## Interaction

Recall the funnel data model for two regression lines:

$$
\text{tswirl} = \beta_0 + \beta_1 (\text{dist}) + \beta_2 (\text{funnel.hi}) + \beta_3 (\text{dist}\cdot \text{funnel.hi}) + \epsilon
$$

- The product term `\(\beta_3 (\text{dist}\cdot \text{funnel.hi})\)` allows for different effects of distance for low and high settings.

--

&lt;br&gt;

**Interaction:** When the relationship between two variables changes depending on a third variable.

  - Consider adding a product term to account for interactions where the context suggests it.

---

## Fish Weight Analysis
### Example 3.11

- **Dataset:** **.red[Perch]** (measurements for 56 fish)

  - **Predictors:** `Length`, `Width` (in cm)
  
  - **Response:** `Weight` (in gm)

&lt;br&gt;

* Fit a two-predictor model with an interaction.

* Question: Why might the product of the two explanatory variables be important here? What does the product represent?

---
### Example R Code for **.red[Perch]** Data


.panelset[

.panel[.panel-name[Code]

```r
data("Perch")
perch_mod &lt;- lm(Weight ~ Length + Width + I(Length * Width), data = Perch)
summary(perch_mod)
```



]

.panel[.panel-name[Output]

```
## 
## Call:
## lm(formula = Weight ~ Length + Width + I(Length * Width), data = Perch)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -140.106  -12.226    1.230    8.489  181.408 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       113.9349    58.7844   1.938    0.058 .  
## Length             -3.4827     3.1521  -1.105    0.274    
## Width             -94.6309    22.2954  -4.244 9.06e-05 ***
## I(Length * Width)   5.2412     0.4131  12.687  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 44.24 on 52 degrees of freedom
## Multiple R-squared:  0.9847,	Adjusted R-squared:  0.9838 
## F-statistic:  1115 on 3 and 52 DF,  p-value: &lt; 2.2e-16
```



]
]

---

### Example R Code for **.red[Perch]** Data

Points to note:

- Use of `I()` to create product term without creating a new variable.

- Interpretation of coefficient of interaction.

  - Compare "effect" of an increase in `Width` for different values of `Length`
  
  - For example: write the model for different values of `Length` (e.g., 20 cm and 40 cm)
  
  - Note difference in effect of an extra 1cm in `Width`.
  
---
### Example R Code for **.red[Perch]** Data

.panelset[

.panel[.panel-name[Code]

```r
anova(perch_mod)
```



]

.panel[.panel-name[Output]

```
## Analysis of Variance Table
## 
## Response: Weight
##                   Df  Sum Sq Mean Sq  F value    Pr(&gt;F)    
## Length             1 6118739 6118739 3126.571 &lt; 2.2e-16 ***
## Width              1  110593  110593   56.511 7.416e-10 ***
## I(Length * Width)  1  314997  314997  160.958 &lt; 2.2e-16 ***
## Residuals         52  101765    1957                       
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```



]
]

---
### Example R Code for **.red[Perch]** Data

.panelset[

.panel[.panel-name[Code]

```r
gf_point(resid(perch_mod) ~ fitted(perch_mod)) %&gt;%
  gf_hline(yintercept = ~0, col = "red")
```



]

.panel[.panel-name[Output]

&lt;img src="Ch3Lect_pt3_files/figure-html/unnamed-chunk-4-1.png" width="90%" /&gt;

]
]

-  Consider `log(Weight)` given non-constant variance.

---

### Example: State SAT Scores

**Response variable `\((Y)\)`:** 
  - `SAT` state average combined SAT score
  
**Potential predictors `\((X)\)`:**

  - `Takers`: % taking SAT exam
  
  - `Expend`: spending per student ($100s)
  
&lt;br&gt;

**Data:** **.red[state_sat]**


---

### Results of Fitting Linear Model

.pull-left[
&lt;img src="Ch3Lect_pt3_files/figure-html/unnamed-chunk-5-1.png" width="90%" /&gt;

]

.pull-right[
&lt;img src="Ch3Lect_pt3_files/figure-html/unnamed-chunk-6-1.png" width="90%" /&gt;

]

&lt;br&gt;

`\(\Longrightarrow\)` Consider a "curved" line.

---

## Polynomial Regression

For a single predictor `\(X\)`, consider:

$$
`\begin{align}
Y &amp;= \beta_0 + \beta_1 X + \beta_2 X^2 + \cdots + \beta_p X^p + \epsilon\\[1ex]
Y &amp;= \beta_0 + \beta_1 X + \epsilon \text{(linear)}\\[1ex]
Y &amp;= \beta_0 + \beta_1 X + \beta_2 X^2 +\epsilon \text{(quadratic)}\\[1ex]
Y &amp;= \beta_0 + \beta_1 X + \beta_2 X^2 +\beta_3 X^3 +\epsilon \text{(cubic)}
\end{align}`
$$

&lt;br&gt;

**Caution:** Beware of "overfitting" with large powers `\(p\)`.

---

## Fitting a Polynomial Regression in R

**Method 1:** 

  - Use `mutate()` to create new columns with the powers of the predictor variable.

--

**Method 2:** 

  - To avoid creating a new column in the data, use `I()` in the `lm()` specification:


```r
quadmod &lt;- lm(SAT ~ Takers + I(Takers^2), data = state_sat)
```

---

## Quadratic Model for SAT

.panelset[

.panel[.panel-name[Code]

```r
state_sat &lt;- read.csv("http://people.kzoo.edu/enordmoe/math360/StateSAT.csv")
quadmod &lt;- lm(SAT ~ Takers + I(Takers^2), data = state_sat)
summary(quadmod)
```



]

.panel[.panel-name[Output]

```
## 
## Call:
## lm(formula = SAT ~ Takers + I(Takers^2), data = state_sat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -83.015 -16.636   0.783  22.167  55.714 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 1053.13112    9.27372 113.561  &lt; 2e-16 ***
## Takers        -7.16159    0.89220  -8.027 2.32e-10 ***
## I(Takers^2)    0.07102    0.01405   5.055 6.99e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 29.93 on 47 degrees of freedom
## Multiple R-squared:  0.8289,	Adjusted R-squared:  0.8216 
## F-statistic: 113.8 on 2 and 47 DF,  p-value: &lt; 2.2e-16
```



]
]

.red[Fitted model]: `\(\quad\widehat{\text{SAT}} = 1053.1 -7.161(\text{Takers})+0.0710(\text{Takers}^2)\)`

---

## SAT data: Plot the Quadratic Model

.panelset[

.panel[.panel-name[Code]

```r
# Use the name of the fitted lm model 
quad_curve &lt;- makeFun(quadmod) 
gf_point(SAT ~ Takers, data = state_sat) %&gt;%
  gf_function(quad_curve, color = "red")
```



]

.panel[.panel-name[Output]

&lt;img src="Ch3Lect_pt3_files/figure-html/unnamed-chunk-9-1.png" width="90%" /&gt;

]
]

---

## SAT Data: Residual Plot

.panelset[

.panel[.panel-name[Code]

```r
# Use the name of the fitted lm model 
gf_point(resid(quadmod) ~ fitted(quadmod)) %&gt;%
  gf_hline(yintercept = ~ 0, color = "red")
```



]

.panel[.panel-name[Output]

&lt;img src="Ch3Lect_pt3_files/figure-html/unnamed-chunk-10-1.png" width="90%" /&gt;

]
]

---

## Guidelines for Choosing the Polynomial Degree

- Use the minimum degree needed to capture the structure of the data.

- Check the `\(t\)` test of the coefficient for the highest power.

- Keep lower powers even if they are not "significant."

---
background-image: url(https://www.liverpool.ac.uk/pfg/Who/Blog/files/2088_c953_512.gif)
background-size: contain

---

### Complete Second Order Models

**Definition:** A complete second-order model for two predictors would be
$$
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_1^2 + \beta_4 X_2^2 + \beta_5 X_1X_2 + \epsilon
$$

- Allows for curvature in both variables and the possibility of interaction.

- Linear and quadratic models can be obtained by setting certain `\(\beta_i=0\)`.

&lt;br&gt;

**Example**: Try a full second-order model for SAT data


---
class: inverse

### Visualizing Second-Order Models

&lt;img src="figures/second_order.png" width="65%" style="display: block; margin: auto;" /&gt;

---

### Example: Second Order Model for SAT Data

.panelset[

.panel[.panel-name[Code]

```r
sat_second &lt;- lm(SAT ~ Takers + Expend + I(Takers^2) 
                 + I(Expend^2) + I(Takers*Expend), data = state_sat)
summary(sat_second)
```



]

.panel[.panel-name[Output]

```
## 
## Call:
## lm(formula = SAT ~ Takers + Expend + I(Takers^2) + I(Expend^2) + 
##     I(Takers * Expend), data = state_sat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -50.472 -13.535   1.023   8.866  60.870 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)        893.66283   36.14094  24.727  &lt; 2e-16 ***
## Takers              -7.05561    0.83740  -8.426 9.96e-11 ***
## Expend              10.33333    2.49600   4.140 0.000155 ***
## I(Takers^2)          0.07725    0.01328   5.816 6.28e-07 ***
## I(Expend^2)         -0.11775    0.04426  -2.660 0.010851 *  
## I(Takers * Expend)  -0.03344    0.03716  -0.900 0.373087    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 23.68 on 44 degrees of freedom
## Multiple R-squared:  0.8997,	Adjusted R-squared:  0.8883 
## F-statistic: 78.96 on 5 and 44 DF,  p-value: &lt; 2.2e-16
```



]
]

---

### Example: Can the model be simplified?

- Do we need the interaction? 

- Do we need both quadratic terms?

- Do we even need the `Expend` terms?  

**Stay tuned** for the nested `\(F\)` test (Section 3.6)

---
class: inverse, middle, center

## Multicollinearity

---

## Mulitcollinearity

- What is it?

--

  - Two or more predictors are strongly associated with each other.
  
--
  
- Why is it a problem?

--

  - Individual coefficients and `\(t\)` tests can be deceptive and unreliable.

--

&lt;br&gt;


**Bad news:** No cures, just treatments!
---

### Effects of Multicollinearity

- If predictors are highly correlated among themselves:

1. The regression coefficients and tests can be extremely variable and difficult to interpret individually.

1. One variable alone might work as well as many.

&lt;br&gt;

- Approach may depend on the goal of the analysis: description vs prediction.

---

## How to Detect Multicollinearity?
### 1. Correlation Matrix

- **Dataset:** **.red[MidtermFinalA]** (class scores)

  - **Response:** `Final` exam score

  - **Predictors:** `Quiz` average, `Class` participation, and `Midterm` score
  
---

### Correlation Matrix for MidtermFinalA

- Note high correlation between `Midterm` and `Quiz`

.panelset[

.panel[.panel-name[Code]

```r
MidtermFinalA &lt;- read.csv("http://people.kzoo.edu/enordmoe/math360/MidtermFinalA.csv")
options(digits = 3)
M &lt;- MidtermFinalA %&gt;%
  select(Midterm, Final, Quiz, Class) %&gt;%
  cor()
M
# or use cor(MidtermFinalA[2:5])
options(digits=5)
```



]

.panel[.panel-name[Output]

```
##         Midterm Final  Quiz Class
## Midterm   1.000 0.754 0.972 0.279
## Final     0.754 1.000 0.743 0.144
## Quiz      0.972 0.743 1.000 0.234
## Class     0.279 0.144 0.234 1.000
```



]
]

---

### Multicollinearity: Simulation

- Explore stability of regression results in the presence of multicollinearity

  - `Quiz` and `Midterm` are related
  
  - `Class` participation is independent of the others.
  
- Link to download &lt;a href="https://www.dropbox.com/s/w9y31uny2tyejwd/SimMultiFinal.R" download&gt;SimMultiFinal.R&lt;/a&gt;

---

## How to Detect Multicollinearity?
### 2. Variance Inflation Factor (VIF)

$$
\text{VIF} = \frac{1}{1-R_i^2} 
$$
where `\(R_i^2\)` is the `\(R^2\)` for the regression predicting variable `\(X_i\)` from the other *predictor variables*.

&lt;br&gt;

**Beware** if `\(\text{VIF}&gt;5\)` `\(\Longleftrightarrow\)` `\(R_i^2&gt;80\%\)`.

&lt;br&gt;

- Obtain `\(\text{VIF}\)` using **car** package in R.

---

### Example: MidtermFinalA Dataset

.panelset[

.panel[.panel-name[Code]

```r
finalmodel &lt;- lm(Final ~ Midterm + Quiz + Class, data = MidtermFinalA)
summary(finalmodel)
#install.packages(car)
library(car)
vif(finalmodel)
```



]

.panel[.panel-name[Output]

```
## 
## Call:
## lm(formula = Final ~ Midterm + Quiz + Class, data = MidtermFinalA)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -19.35  -6.17   0.41   5.90  17.41 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)   19.158      9.679    1.98    0.058 .
## Midterm        1.271      1.091    1.17    0.254  
## Quiz           0.499      2.024    0.25    0.807  
## Class         -0.117      0.232   -0.51    0.616  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 9.93 on 27 degrees of freedom
## Multiple R-squared:  0.575,	Adjusted R-squared:  0.527 
## F-statistic: 12.2 on 3 and 27 DF,  p-value: 3.22e-05
## 
## Midterm    Quiz   Class 
## 19.2840 18.8098  1.1158
```



]
]

---

### Output for Checking VIF calculation

- The calculation agrees up to rounding: 
`\(\text{VIF} = \frac{1}{1-.948} = 19.23\)`

.panelset[

.panel[.panel-name[Code]

```r
summary(lm(Midterm  ~  Quiz + Class, data = MidtermFinalA))
```



]

.panel[.panel-name[Output]

```
## 
## Call:
## lm(formula = Midterm ~ Quiz + Class, data = MidtermFinalA)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.478 -1.127  0.141  1.004  3.939 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   2.9568     1.5812    1.87    0.072 .  
## Quiz          1.8026     0.0832   21.67   &lt;2e-16 ***
## Class         0.0484     0.0391    1.24    0.226    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.72 on 28 degrees of freedom
## Multiple R-squared:  0.948,	Adjusted R-squared:  0.944 
## F-statistic:  256 on 2 and 28 DF,  p-value: &lt;2e-16
```



]
]


---

### What to Do if You Have Multicollinearity?

1. Choose a better set of predictors.

1. Eliminate some of the redundant predictors.

1. Combine predictors to create a (possibly weighted) scale.

1. "Ignore" the individual coefficients and tests if prediction is the primary goal.

&lt;br&gt;

- Best remedies depend on the purpose of the analysis.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
